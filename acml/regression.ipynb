{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d7af76",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7babd0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e1e2a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "class LinearRegression():\n",
    "  def __init__(self, n_iter: int, lr: float) -> None:\n",
    "    self.nr_iterations = n_iter\n",
    "    self.learning_rate = lr\n",
    "  \n",
    "  def initialize_weights(self, n_features):\n",
    "    \"\"\" Initialize weights randomly [-1/N, 1/N] \"\"\"\n",
    "    limit = 1 / math.sqrt(n_features)\n",
    "    self.w = np.random.uniform(-limit, limit, (n_features, ))\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    X = np.insert(X, 0, 1, axis=1)\n",
    "    self.training_errors = []\n",
    "    # initalize weights\n",
    "    self.w = np.zeros(X.shape[1])\n",
    "\n",
    "    for _ in range(self.nr_iterations):\n",
    "      y_pred = X.dot(self.w)\n",
    "      mse = np.mean(0.5 * np.square(y - y_pred))  # 0.5 makes derivation more convenient (^2)\n",
    "      print(mse)\n",
    "      self.training_errors.append(mse)\n",
    "\n",
    "      grad_w = -(y - y_pred).dot(X)\n",
    "      # print(grad_w)\n",
    "      # Update the weights\n",
    "      self.w -= self.learning_rate * grad_w\n",
    "\n",
    "    print(self.training_errors)\n",
    "\n",
    "  def predict(self, X):\n",
    "    # Insert constant ones for bias weights\n",
    "    X = np.insert(X, 0, 1, axis=1)\n",
    "    y_pred = X.dot(self.w)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3745abc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5],\n",
       "       [4.9, 3. ],\n",
       "       [4.7, 3.2],\n",
       "       [4.6, 3.1],\n",
       "       [5. , 3.6],\n",
       "       [5.4, 3.9],\n",
       "       [4.6, 3.4],\n",
       "       [5. , 3.4],\n",
       "       [4.4, 2.9],\n",
       "       [4.9, 3.1],\n",
       "       [5.4, 3.7],\n",
       "       [4.8, 3.4],\n",
       "       [4.8, 3. ],\n",
       "       [4.3, 3. ],\n",
       "       [5.8, 4. ],\n",
       "       [5.7, 4.4],\n",
       "       [5.4, 3.9],\n",
       "       [5.1, 3.5],\n",
       "       [5.7, 3.8],\n",
       "       [5.1, 3.8],\n",
       "       [5.4, 3.4],\n",
       "       [5.1, 3.7],\n",
       "       [4.6, 3.6],\n",
       "       [5.1, 3.3],\n",
       "       [4.8, 3.4],\n",
       "       [5. , 3. ],\n",
       "       [5. , 3.4],\n",
       "       [5.2, 3.5],\n",
       "       [5.2, 3.4],\n",
       "       [4.7, 3.2],\n",
       "       [4.8, 3.1],\n",
       "       [5.4, 3.4],\n",
       "       [5.2, 4.1],\n",
       "       [5.5, 4.2],\n",
       "       [4.9, 3.1],\n",
       "       [5. , 3.2],\n",
       "       [5.5, 3.5],\n",
       "       [4.9, 3.6],\n",
       "       [4.4, 3. ],\n",
       "       [5.1, 3.4],\n",
       "       [5. , 3.5],\n",
       "       [4.5, 2.3],\n",
       "       [4.4, 3.2],\n",
       "       [5. , 3.5],\n",
       "       [5.1, 3.8],\n",
       "       [4.8, 3. ],\n",
       "       [5.1, 3.8],\n",
       "       [4.6, 3.2],\n",
       "       [5.3, 3.7],\n",
       "       [5. , 3.3],\n",
       "       [7. , 3.2],\n",
       "       [6.4, 3.2],\n",
       "       [6.9, 3.1],\n",
       "       [5.5, 2.3],\n",
       "       [6.5, 2.8],\n",
       "       [5.7, 2.8],\n",
       "       [6.3, 3.3],\n",
       "       [4.9, 2.4],\n",
       "       [6.6, 2.9],\n",
       "       [5.2, 2.7],\n",
       "       [5. , 2. ],\n",
       "       [5.9, 3. ],\n",
       "       [6. , 2.2],\n",
       "       [6.1, 2.9],\n",
       "       [5.6, 2.9],\n",
       "       [6.7, 3.1],\n",
       "       [5.6, 3. ],\n",
       "       [5.8, 2.7],\n",
       "       [6.2, 2.2],\n",
       "       [5.6, 2.5],\n",
       "       [5.9, 3.2],\n",
       "       [6.1, 2.8],\n",
       "       [6.3, 2.5],\n",
       "       [6.1, 2.8],\n",
       "       [6.4, 2.9],\n",
       "       [6.6, 3. ],\n",
       "       [6.8, 2.8],\n",
       "       [6.7, 3. ],\n",
       "       [6. , 2.9],\n",
       "       [5.7, 2.6],\n",
       "       [5.5, 2.4],\n",
       "       [5.5, 2.4],\n",
       "       [5.8, 2.7],\n",
       "       [6. , 2.7],\n",
       "       [5.4, 3. ],\n",
       "       [6. , 3.4],\n",
       "       [6.7, 3.1],\n",
       "       [6.3, 2.3],\n",
       "       [5.6, 3. ],\n",
       "       [5.5, 2.5],\n",
       "       [5.5, 2.6],\n",
       "       [6.1, 3. ],\n",
       "       [5.8, 2.6],\n",
       "       [5. , 2.3],\n",
       "       [5.6, 2.7],\n",
       "       [5.7, 3. ],\n",
       "       [5.7, 2.9],\n",
       "       [6.2, 2.9],\n",
       "       [5.1, 2.5],\n",
       "       [5.7, 2.8],\n",
       "       [6.3, 3.3],\n",
       "       [5.8, 2.7],\n",
       "       [7.1, 3. ],\n",
       "       [6.3, 2.9],\n",
       "       [6.5, 3. ],\n",
       "       [7.6, 3. ],\n",
       "       [4.9, 2.5],\n",
       "       [7.3, 2.9],\n",
       "       [6.7, 2.5],\n",
       "       [7.2, 3.6],\n",
       "       [6.5, 3.2],\n",
       "       [6.4, 2.7],\n",
       "       [6.8, 3. ],\n",
       "       [5.7, 2.5],\n",
       "       [5.8, 2.8],\n",
       "       [6.4, 3.2],\n",
       "       [6.5, 3. ],\n",
       "       [7.7, 3.8],\n",
       "       [7.7, 2.6],\n",
       "       [6. , 2.2],\n",
       "       [6.9, 3.2],\n",
       "       [5.6, 2.8],\n",
       "       [7.7, 2.8],\n",
       "       [6.3, 2.7],\n",
       "       [6.7, 3.3],\n",
       "       [7.2, 3.2],\n",
       "       [6.2, 2.8],\n",
       "       [6.1, 3. ],\n",
       "       [6.4, 2.8],\n",
       "       [7.2, 3. ],\n",
       "       [7.4, 2.8],\n",
       "       [7.9, 3.8],\n",
       "       [6.4, 2.8],\n",
       "       [6.3, 2.8],\n",
       "       [6.1, 2.6],\n",
       "       [7.7, 3. ],\n",
       "       [6.3, 3.4],\n",
       "       [6.4, 3.1],\n",
       "       [6. , 3. ],\n",
       "       [6.9, 3.1],\n",
       "       [6.7, 3.1],\n",
       "       [6.9, 3.1],\n",
       "       [5.8, 2.7],\n",
       "       [6.8, 3.2],\n",
       "       [6.7, 3.3],\n",
       "       [6.7, 3. ],\n",
       "       [6.3, 2.5],\n",
       "       [6.5, 3. ],\n",
       "       [6.2, 3.4],\n",
       "       [5.9, 3. ]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data[:, :2]\n",
    "y = data.target\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "73a6764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2, 3], [1, 2, 3]])\n",
    "y = np.array([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d51dfc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25\n",
      "0.6762499999999998\n",
      "0.3951125000000001\n",
      "0.25735512500000013\n",
      "0.18985401125\n",
      "0.15677846551250008\n",
      "0.14057144810112499\n",
      "0.13263000956955126\n",
      "0.1287387046890801\n",
      "0.12683196529764926\n",
      "0.12589766299584812\n",
      "0.12543985486796558\n",
      "0.12521552888530313\n",
      "0.12510560915379854\n",
      "0.12505174848536127\n",
      "0.12502535675782703\n",
      "0.12501242481133523\n",
      "0.12500608815755426\n",
      "0.1250029831972016\n",
      "0.12500146176662877\n",
      "0.1250007162656481\n",
      "0.12500035097016757\n",
      "0.1250001719753821\n",
      "0.12500008426793724\n",
      "0.12500004129128925\n",
      "0.12500002023273174\n",
      "0.12500000991403853\n",
      "0.12500000485787888\n",
      "0.12500000238036066\n",
      "0.12500000116637672\n",
      "0.1250000005715246\n",
      "0.12500000028004704\n",
      "0.12500000013722307\n",
      "0.1250000000672393\n",
      "0.12500000003294726\n",
      "0.12500000001614414\n",
      "0.12500000000791064\n",
      "0.1250000000038762\n",
      "0.12500000000189934\n",
      "0.12500000000093067\n",
      "0.12500000000045602\n",
      "0.12500000000022346\n",
      "0.1250000000001095\n",
      "0.12500000000005365\n",
      "0.12500000000002628\n",
      "0.12500000000001288\n",
      "0.1250000000000063\n",
      "0.12500000000000308\n",
      "0.12500000000000153\n",
      "0.12500000000000075\n",
      "0.12500000000000036\n",
      "0.12500000000000017\n",
      "0.12500000000000008\n",
      "0.12500000000000006\n",
      "0.12500000000000003\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "0.125\n",
      "[1.25, 0.6762499999999998, 0.3951125000000001, 0.25735512500000013, 0.18985401125, 0.15677846551250008, 0.14057144810112499, 0.13263000956955126, 0.1287387046890801, 0.12683196529764926, 0.12589766299584812, 0.12543985486796558, 0.12521552888530313, 0.12510560915379854, 0.12505174848536127, 0.12502535675782703, 0.12501242481133523, 0.12500608815755426, 0.1250029831972016, 0.12500146176662877, 0.1250007162656481, 0.12500035097016757, 0.1250001719753821, 0.12500008426793724, 0.12500004129128925, 0.12500002023273174, 0.12500000991403853, 0.12500000485787888, 0.12500000238036066, 0.12500000116637672, 0.1250000005715246, 0.12500000028004704, 0.12500000013722307, 0.1250000000672393, 0.12500000003294726, 0.12500000001614414, 0.12500000000791064, 0.1250000000038762, 0.12500000000189934, 0.12500000000093067, 0.12500000000045602, 0.12500000000022346, 0.1250000000001095, 0.12500000000005365, 0.12500000000002628, 0.12500000000001288, 0.1250000000000063, 0.12500000000000308, 0.12500000000000153, 0.12500000000000075, 0.12500000000000036, 0.12500000000000017, 0.12500000000000008, 0.12500000000000006, 0.12500000000000003, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125]\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [154], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m LinearRegression(n_iter\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[1;32m      2\u001b[0m model\u001b[39m.\u001b[39mfit(X, y)\n\u001b[0;32m----> 3\u001b[0m model\u001b[39m.\u001b[39;49mpredict(np\u001b[39m.\u001b[39;49marray([\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m]))\n",
      "Cell \u001b[0;32mIn [151], line 34\u001b[0m, in \u001b[0;36mLinearRegression.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m     33\u001b[0m   \u001b[39m# Insert constant ones for bias weights\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m   X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49minsert(X, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     35\u001b[0m   y_pred \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw)\n\u001b[1;32m     36\u001b[0m   \u001b[39mreturn\u001b[39;00m y_pred\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36minsert\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/function_base.py:5297\u001b[0m, in \u001b[0;36minsert\u001b[0;34m(arr, obj, values, axis)\u001b[0m\n\u001b[1;32m   5295\u001b[0m     axis \u001b[39m=\u001b[39m ndim \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   5296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 5297\u001b[0m     axis \u001b[39m=\u001b[39m normalize_axis_index(axis, ndim)\n\u001b[1;32m   5298\u001b[0m slobj \u001b[39m=\u001b[39m [\u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m)]\u001b[39m*\u001b[39mndim\n\u001b[1;32m   5299\u001b[0m N \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mshape[axis]\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(n_iter=100, lr=0.01)\n",
    "model.fit(X, y)\n",
    "model.predict(np.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8944884a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0.]), 1.5)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X, y)\n",
    "lr.coef_, lr.intercept_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
